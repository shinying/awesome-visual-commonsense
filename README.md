# Awesome Visual Commonsense

This is a curated list of resources about learning visual commonsense. Some datasets in pure texts are included as they might help expand commonsense knowledge. 

## Testbed

### Vision

* [Visual Choice of Plausible Alternatives: An Evaluation of Image-based Commonsense Causal Reasoning (LREC 2018)](https://www.aclweb.org/anthology/L18-1316/)
* [From Recognition to Cognition: Visual Commonsense Reasoning (CVPR 2019)](https://visualcommonsense.com/)

* [What is More Likely to Happen Next? Video-and-Language Future Event Prediction (EMNLP 2020)](https://www.aclweb.org/anthology/2020.emnlp-main.706)

* [Vis-Causal: Learning Contextual Causality from Time-consecutive Images](https://arxiv.org/abs/2012.07138)

### Language

* [SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference (EMNLP 2018)](https://rowanzellers.com/swag/)
* [HellaSwag: Can a Machine Really Finish Your Sentence? (ACL 2019)](https://rowanzellers.com/hellaswag/)

## Knowledge Graph

### Vision

* [VisualCOMET: Reasoning about the Dynamic Context of a Still Image (ECCV 2020)](https://visualcomet.xyz/)

### Language

* [ConceptNet (AAAI 2017)](https://conceptnet.io/)
* [ATOMIC (AAAI 2019)](https://allenai.org/data/atomic)
* [TransOMCS (IJCAI 2020)](https://arxiv.org/abs/2005.00206)
* [ATOMIC 2020 (AAAI 2021)](https://allenai.org/data/atomic-2020) : The comparison with the above datasets can be found in the paper.

## Tutorials and Talks

* [ACL 2020 Commonsense Tutorial](https://homes.cs.washington.edu/~msap/acl2020-commonsense/)
* [Intuitive reasoning as (un)supervised language generation - Yejin Choi](https://www.youtube.com/watch?v=QN_LUgU9-kg)
* [Learning representations of semantic concepts and their causal relationships: Inspiration from conscious processing - Yoshua Bengio](https://www.youtube.com/watch?v=u3IR6sSwwjg)

## Implicit Knowledge Resources



